{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter, ImageChops\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "import scipy\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_state_dict(torch.load('mnist.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeepDream():\n",
    "    '''\n",
    "    Given a network, input size to the network and channel wise mean,std of the data it was trained on,\n",
    "    label specific 'deep dream' images can be created\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self,net,input_size,data_mean=None,data_std=None,use_gaussian_filter=False):\n",
    "        self.device = None\n",
    "        self.net = net\n",
    "        self.input_size = input_size\n",
    "        self.data_mean = data_mean\n",
    "        self.data_std = data_std\n",
    "        self.input_2d = False\n",
    "        self.input_3d = False\n",
    "        self.ouputImage = None\n",
    "        self.use_gaussian_filter = use_gaussian_filter\n",
    "        # list variables used in randomDream method\n",
    "        self.labels = [i for i in range(1000)]\n",
    "        # set methods\n",
    "        self.setDevice()\n",
    "        self.setNetwork()\n",
    "        self.check_input()\n",
    "        if self.use_gaussian_filter == True:\n",
    "            print(\"Gaussian filter will be used\")\n",
    "            self.gaussian_filter = None\n",
    "            self.setGaussianFilter()\n",
    "\n",
    "    def setDevice(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"Device used to run this program: \",self.device)\n",
    "\n",
    "\n",
    "    def setNetwork(self):\n",
    "        print(\"Loading the network...\")\n",
    "        \n",
    "        self.net.eval() # inference mode\n",
    "\n",
    "        self.net.to(self.device)\n",
    "        print(\"Network Loaded\")\n",
    "        \n",
    "    def check_input(self):\n",
    "        assert len(self.input_size) == 3\n",
    "        if self.input_size[0] == 1: self.input_2d = True\n",
    "        else: self.input_3d = True\n",
    "        if self.input_2d:   \n",
    "            if self.data_mean is None: \n",
    "                self.data_mean = 0.5\n",
    "                print(\"Data means set at 0.5 by default\")\n",
    "            if self.data_std is None: \n",
    "                self.data_std = 0.5\n",
    "                print(\"Data standard deviation set at 0.5 by default\")\n",
    "\n",
    "\n",
    "    def __call__(self,im=None,label=0,nItr=100,lr=0.1):\n",
    "        \"\"\"Does activation maximization on a specific label for specified iterations,\n",
    "           acts like a functor, and returns an image tensor\n",
    "        \"\"\"\n",
    "\n",
    "        if im is None:\n",
    "            im = self.createInputImage()\n",
    "            im = self.prepInputImage(im)\n",
    "            im = im.to(self.device)\n",
    "\n",
    "            im = Variable(im.unsqueeze(0),requires_grad=True)\n",
    "\n",
    "        softmaxed_activation = F.softmax(self.net(im),dim=1)\n",
    "        val,index = softmaxed_activation.max(1)\n",
    "        print(\"Probablity before optimizing : {} and label {}\".format(val[0],index[0]))\n",
    "        print(\"Dreaming...\")\n",
    "\n",
    "        for i in range(nItr):\n",
    "\n",
    "            out = self.net(im)\n",
    "            #loss = -out[0,label]\n",
    "            loss = out[0,label]\n",
    "            loss.backward()\n",
    "\n",
    "            avg_grad = np.abs(im.grad.data.cpu().numpy()).mean()\n",
    "            norm_lr = lr / (avg_grad + 1e-20)\n",
    "            im.data += norm_lr * im.grad.data\n",
    "            im.data = torch.clamp(im.data,-1,1)\n",
    "            \n",
    "            if self.use_gaussian_filter == True:\n",
    "                im.data = self.gaussian_filter(im.data)\n",
    "\n",
    "            im.grad.data.zero_()\n",
    "        \n",
    "        softmaxed_activation = F.softmax(self.net(im),dim=1)\n",
    "        val,index = softmaxed_activation.max(1)\n",
    "        print(\"Probablity after optimizing : {} and label {}\".format(val[0],index[0]))\n",
    "\n",
    "        return im\n",
    "\n",
    "    def randomDream(self,im=None,randomSeed=0):\n",
    "        \"\"\"Does activation maximization on a random label for randomly chosen learning rate,number of iterations and gaussian filter size, and returns an image tensor\n",
    "        \"\"\"\n",
    "        random.seed(randomSeed)\n",
    "        rand_nItr = np.asscalar(np.random.normal(500,40,1).astype(int))\n",
    "        rand_lr = np.asscalar(np.random.normal(0.12,0.01,1))\n",
    "        rand_label = random.choice(self.labels)\n",
    "        if self.use_gaussian_filter == True:\n",
    "            rand_sigma = np.asscalar(np.random.normal(0.45,0.05,1))\n",
    "            self.setGaussianFilter(sigma=rand_sigma)\n",
    "\n",
    "        im = self.__call__(im,label=rand_label,nItr=rand_nItr,lr=rand_lr)\n",
    "\n",
    "        return im\n",
    "\n",
    "\n",
    "    def createInputImage(self):\n",
    "        if self.input_2d:\n",
    "            input_size = (self.input_size[1],self.input_size[2])\n",
    "            zeroImage_np = np.ones(input_size)*127\n",
    "            zeroImage = Image.fromarray((zeroImage_np).astype('uint8'),'L')\n",
    "\n",
    "        return zeroImage\n",
    "\n",
    "    def prepInputImage(self,inputImage):\n",
    "        if self.input_2d:\n",
    "            if (self.data_mean is not None) and (self.data_std is not None):\n",
    "                preprocess = transforms.Compose([\n",
    "                transforms.Grayscale(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.data_mean,self.data_std),\n",
    "                ])\n",
    "\n",
    "        return preprocess(inputImage)\n",
    "\n",
    "    def postProcess(self,image):\n",
    "        image_tensor = torch.squeeze(image.data) # remove the batch dimension\n",
    "        if self.input_2d:\n",
    "    #        image_tensor.transpose_(0,1) # convert from CxHxW to HxWxC format\n",
    "    #        image_tensor.transpose_(1,2)\n",
    "            image_tensor = image_tensor*self.data_std[0] + self.data_mean[0] # std and mean for mjsynth \n",
    "\n",
    "            image_tensor = image_tensor.cpu() # back to host\n",
    "\n",
    "            img = Image.fromarray((image_tensor.data.numpy()*255).astype('uint8'), 'L') #torch tensor to PIL image_tensor\n",
    "\n",
    "        return img\n",
    "\n",
    "    def show(self,img):\n",
    "#         plt.figure(num=1, figsize=(12, 8), dpi=120, facecolor='w', edgecolor='k')\n",
    "        plt.imshow(img,'gray')\n",
    "\n",
    "    def save(self,image,fileName):\n",
    "        #image = image.resize((32,256), Image.ANTIALIAS)\n",
    "        image.save(fileName,'PNG')\n",
    "        print('{} saved'.format(fileName))\n",
    "\n",
    "    def setGaussianFilter(self,kernelSize=3,sigma=0.5):\n",
    "        if self.input_2d:\n",
    "            # Create a x, y coordinate grid of shape (kernelSize, kernelSize, 2)\n",
    "            x_cord = torch.arange(kernelSize)\n",
    "            x_grid = x_cord.repeat(kernelSize).view(kernelSize, kernelSize)\n",
    "            y_grid = x_grid.t()\n",
    "            xy_grid = torch.stack([x_grid, y_grid], dim=-1)\n",
    "            xy_grid = xy_grid.float()\n",
    "\n",
    "            mean = (kernelSize - 1)/2.\n",
    "            variance = sigma**2.\n",
    "\n",
    "\n",
    "            # Calculate the 2-dimensional gaussian kernel which is\n",
    "            # the product of two gaussian distributions for two different\n",
    "            # variables (in this case called x and y)\n",
    "            gaussian_kernel = (1./(2.*math.pi*variance)) * torch.exp(-torch.sum((xy_grid - mean)**2., dim=-1) /(2*variance))\n",
    "            # Make sure sum of values in gaussian kernel equals 1.\n",
    "            gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "            # Reshape to 2d depthwise convolutional weight\n",
    "            gaussian_kernel = gaussian_kernel.view(1, 1, kernelSize, kernelSize)\n",
    "#             gaussian_kernel = gaussian_kernel.repeat(3, 1, 1, 1)\n",
    "\n",
    "            pad = math.floor(kernelSize/2)\n",
    "\n",
    "            gauss_filter = nn.Conv2d(in_channels=1, out_channels=1,padding=pad,\n",
    "                                kernel_size=kernelSize, groups=1, bias=False)\n",
    "\n",
    "            gauss_filter.weight.data = gaussian_kernel\n",
    "            gauss_filter.weight.requires_grad = False\n",
    "            self.gaussian_filter = gauss_filter.to(self.device)\n",
    "            #print(\"gaussian_filter created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used to run this program:  cpu\n",
      "Loading the network...\n",
      "Network Loaded\n",
      "Gaussian filter will be used\n"
     ]
    }
   ],
   "source": [
    "dreamer = DeepDream(network,(1,28,28),(0.13,),(0.31,),use_gaussian_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dreamer.data_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elias/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity before optimizing : 0.13195645809173584 and label 8\n",
      "Dreaming...\n",
      "Probablity after optimizing : 0.9916484355926514 and label 9\n"
     ]
    }
   ],
   "source": [
    "dream = dreamer(label=9,nItr=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dreamer.postProcess(dream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFApJREFUeJzt3V+MVPd1B/Dv8drYsKz5z7KGFRiMsJBNSbVCRbHqVHGwgyPhvFjhIaaSFfIQS42Uh1ruQ/1oVU0iP1SRSI2Cq9RJpcQyD1Yb14pkRbIiY4T/ENfg8kcsApb/ZvljYDl92Eu0xnvPd3buzNxxz/cjIXbnzJ35zZ179s6d8/tj7g4Ryee2uhsgIvVQ8oskpeQXSUrJL5KUkl8kKSW/SFJKfpGklPwiSSn5RZK6vZNP1tPT4z09PU1v3629Ec2s7iaUqtq2GzduhPF2vies7VXj7VTXc1+7dg1jY2MNPXml5DezxwC8CKAHwL+6+wvR/Xt6erBo0aLS+NjYWPh8UbzdB2n0R+u22+IPUCzezgNl2rRpYZzttytXrlSKR/ud7RfWdhZnjx9h70nV97yKaJ8ODw83/DhNt9DMegD8C4BvAlgNYLOZrW728USks6r8eVoH4BN3P+DuVwH8CsCm1jRLRNqtSvIvBnBkwu/DxW2fY2ZbzWyXme1iHzFFpHPa/m2/u29z9yF3H2rndZCITE2VbDwKYHDC70uK20TkS6BK8r8DYKWZ3Wtm0wB8B8DO1jRLRNqt6VKfu183s2cA/BfGS33b3X0v2y4q1127di3c9urVq009biPxKmUn1neBxauWAqPtb789fourlkgvXboUxqP3jJXqGPba2lmeZc/N4pHr169XijeqUp3f3V8H8HpLWiIiHaVv4ESSUvKLJKXkF0lKyS+SlJJfJCklv0hSHR3P7+5hXZnV4qOacZU+Ao248847m4oBwB133BHGq8xx0MjjR1jN+MKFC2F8dHQ0jEf9AKZPnx5uO2vWrDB+1113hfGoH0HV4cBV+wFE2LHaqjkUdOYXSUrJL5KUkl8kKSW/SFJKfpGklPwiSXW01AfEZYoqw3JZqY+VpNjQ1qjkxUpOrKTFSjesFBiV+mbMmBFuy14326+nTp0K49F+Z/vt5MmTYZyVAqO2z5w5M9yWxauWAqM4K79GQ7ynMhO0zvwiSSn5RZJS8oskpeQXSUrJL5KUkl8kKSW/SFIdr/NXUWWK6suXL4dx1scgqqWzOj0bcstqs729vWF83rx5pbE5c+aE27I+BOy5WT+CqNbOhq6OjIyE8QMHDoTxhQsXlsYWLFgQbsv6P/T19YXxKtOxd2opep35RZJS8oskpeQXSUrJL5KUkl8kKSW/SFJKfpGkKtX5zewQgAsAxgBcd/chcv+wHs+mwI7irDY6e/bsMM76AUSPz+rVFy9eDONsXDvrgxDV6lkfAzbXAKvjL1u2LIxHU3ez/XL27Nkwzt6zzz77rDR25cqVSo/Npv6usqw6e7+j8f5T6SPQik4+f+Pu8YwOItJ19LFfJKmqye8Afmdm75rZ1lY0SEQ6o+rH/ofc/aiZLQTwhpn9j7u/NfEOxR+FrUD1ZalEpHUqnfnd/Wjx/wiAVwGsm+Q+29x9yN2H2GAHEemcprPRzHrNrO/mzwA2APiwVQ0Tkfaq8rG/H8CrRUnjdgD/7u7/2ZJWiUjbNZ387n4AwF9MZRszC6/72WVBVMNk9U02/zwbv11lie8q/RcA3va5c+eWxqrMBQAA99xzTxhn9e6o1r5x48Zw23379oXxgwcPhvGo/wRrd9X1DNjxOJX59af62I3SRbhIUkp+kaSU/CJJKflFklLyiySl5BdJquNTd7MptiPRUEc2DJKVR1g8KsdVeU0AL/vcfffdYTxqGyv1sZIVG/LLyrPRFNdVl8Fmw4nZtOUR9p6w462KTpUBdeYXSUrJL5KUkl8kKSW/SFJKfpGklPwiSSn5RZLqaJ3fzCotTRxNWRzFAD5Es0o/AVaXjYbcAsDq1avDOKuHR9Nzj46Ohtuyfc5q7WxqtirDaufPnx/G77333jB++vTp0lg0pXgjqg7pjVSZ9nsqdOYXSUrJL5KUkl8kKSW/SFJKfpGklPwiSSn5RZLq+Hj+KmOVo1p8NEU0wKfeZvXqaFw8q0evWbMmjK9atSqMsz4KH3/8cWmMvW62PDjbvr+/P4xHbWePzeYSYNOKR8cLq8OzJbrZe8JUmcI+ik8lv3TmF0lKyS+SlJJfJCklv0hSSn6RpJT8Ikkp+UWSonV+M9sO4FsARtz9geK2uQB+DWAZgEMAnnT3sw08VjjHfZUx+Wx8NaspV1lG+8EHHwy3Xb58eRhn49qjcekA8N5775XG9u/fH267cOHCMD5r1qwwvnTp0jAerTnA5jlYvHhxGGfbX7lypTR25syZcFt2vLD5H1i9vepaD63QyJn/FwAeu+W2ZwG86e4rAbxZ/C4iXyI0+d39LQC3/pncBGBH8fMOAE+0uF0i0mbNXvP3u/ux4ufjAOI+niLSdSpfeLi7m1lpR2kz2wpgK9Ad1zkiMq7ZM/8JMxsAgOL/kbI7uvs2dx9y9yElv0j3aDb5dwLYUvy8BcBrrWmOiHQKTX4zewXA2wBWmdmwmT0N4AUA3zCz/QAeKX4XkS8R+jnc3TeXhL7ezBNGY5FZvXvGjBnNPGVDj83GtQ8MDJTG2DrxrA8Bw2rK+/btK42dP38+3Pbw4cNhvOo8CLNnzy6NbdiwIdyW1flZLT3ab1EfAIC/bjaeP1pLgcXZ5XGVNQEmUg8/kaSU/CJJKflFklLyiySl5BdJSskvklTHl+iOShysPBKV+ljp5tSpU3HjKmAlpyolKYCX66LXzvYLG0bN3hO2fPiiRYtKY48//ni4LSt5sbaPjJR2PKVTc7NyGouz0jKLR1gZslE684skpeQXSUrJL5KUkl8kKSW/SFJKfpGklPwiSXW0zu/uYW2W1ZSj2iiru168eDGMj46OhvFo6Cqrw7MhvWzacTbsNtovbHrrefPmhfH7778/jK9fvz6MP/XUU6UxtgQ3W6qa9WGIavms7wU7Ftn27LX19fWVxthy86x/Q6N05hdJSskvkpSSXyQpJb9IUkp+kaSU/CJJKflFkup4nT+qabNpoKPx3azuymrt586dC+NRXfbgwYPhtnPmzAnjbNw6Wwb7kUceKY2x5cNZPfrRRx8N42zK8+h9YX0zWL179+7dYXzv3r2lMVbH7+3tDeNsHoNoaXKA7/dI1L+B5cFEOvOLJKXkF0lKyS+SlJJfJCklv0hSSn6RpJT8IknROr+ZbQfwLQAj7v5AcdvzAL4H4GRxt+fc/fVGnjCao57NRx6N72Y1Y1aPZuPeBwcHS2Ns3n3WNta/YcWKFWE8WiKczQ/Plppmcfbao7ozG5d+4cKFMH706NEwfvbs2dIYOx5mzZoVxtly8Wwuguj52T5n/UIa1ciZ/xcAHpvk9p+6+9riX0OJLyLdgya/u78F4EwH2iIiHVTlmv8ZM3vfzLabWdx/VUS6TrPJ/zMAKwCsBXAMwI/L7mhmW81sl5ntYteHItI5TSW/u59w9zF3vwHg5wDWBffd5u5D7j7EvtgSkc5pKvnNbGDCr98G8GFrmiMindJIqe8VAF8DMN/MhgH8I4CvmdlaAA7gEIDvt7GNItIGNPndffMkN7/UzJO5e1gXZvXwKvOVs7orG38dte348ePhtqdOnQrjbLw/G6Md1YXZ3PZRLRzg6x2weneVcevDw8NhnLUtwi5B2fHC+k+w+SOi/cLe70uXLpXGWLs/d9+G7yki/68o+UWSUvKLJKXkF0lKyS+SlJJfJKmOTt3NsKWqo5IW25YtwR0t58wenw0tXbRoURhfsmRJGGdlo9OnT5fGWJdqNow6Gi4M8LZHU2SzoavsPWGl4agMyUp10VTtAB9WW2WYNxtuXGUK+4l05hdJSskvkpSSXyQpJb9IUkp+kaSU/CJJKflFkuqqOj+rjUZLNrM6Phv+GdXKAeDIkSNte+633347jLNppD/99NPSGBuqzOr8a9asCeOsFh/tmzNn4nlh2dTd7HiJ+hiwocisHwCr87Oh1NGS8KxWHz026zsxkc78Ikkp+UWSUvKLJKXkF0lKyS+SlJJfJCklv0hSXVXnn8q0w7diNV9WM2ZTWLP5AiKsbaxWHvVvYKJaNwAsXbo0jLPlwdnY86jt7D2pul+iWnxvb2+47cDAQBhn062z4yV6bex4iaawZ3McTKQzv0hSSn6RpJT8Ikkp+UWSUvKLJKXkF0lKyS+SFK3zm9kggJcB9ANwANvc/UUzmwvg1wCWATgE4El3j4vliGv5bIx0VLNmSy5XXZI5em42/prVXlmc7Zdo7PmCBQvCbVeuXBnGFy5cGMajcekAcPLkydIYG8/P3jO2nkE0DwLbLyzO3hNW54/G5LdzqfqJGjnzXwfwI3dfDeCvAPzAzFYDeBbAm+6+EsCbxe8i8iVBk9/dj7n77uLnCwA+ArAYwCYAO4q77QDwRLsaKSKtN6VrfjNbBuArAP4IoN/djxWh4xi/LBCRL4mGk9/MZgL4DYAfuvvnJo3z8YuUSS9UzGyrme0ys11TmV9MRNqroeQ3szswnvi/dPffFjefMLOBIj4AYGSybd19m7sPuftQlYE7ItJaNBtt/KvslwB85O4/mRDaCWBL8fMWAK+1vnki0i6NDOn9KoDvAvjAzPYUtz0H4AUA/2FmTwM4DOBJ9kBmFpbU2CeDaPgom6J69uzZYZyVZqpMA82Gnp4/fz6Ms2mkZ86cWRpjr/u+++4L4/398Vc50bThLM5eNxvyy8pxUdsHBweb3haoXm6LtmeXx1FpeSpLdNPkd/c/ACh7xK83/Ewi0lV0ES6SlJJfJCklv0hSSn6RpJT8Ikkp+UWS6qqpu9kwyajOH9W6AWDevHlhfP369WH84YcfbqpdAK+Fr1q1KoyzJb6jejdb3pvF2RTXbGrwqI8De13ssZmofwR73ex4YvX0KsON2ZLv0TDpqfSi1ZlfJCklv0hSSn6RpJT8Ikkp+UWSUvKLJKXkF0mq43X+qA7JpmqO6uls3HpfX18YZ3Xf6dOnh/EIm6Kajfc/fvx4GI/axurNbOx41WnFo/eU7VPWf4IdL1Gdn82RwOrlrM7P+kdEz89eV9RvZCrj+XXmF0lKyS+SlJJfJCklv0hSSn6RpJT8Ikkp+UWS6qrx/Ew01/nVq1fDbaMlkQE+djyql1eZVx/gfQzYHPFRrZ7V4avWswcGBsL48uXLS2MrVqwIt2X17sWLF4dxtl8jbB0Htt9Y/4noeGX9PqLjgfXLmEhnfpGklPwiSSn5RZJS8oskpeQXSUrJL5KUkl8kKVrnN7NBAC8D6AfgALa5+4tm9jyA7wG4OYn4c+7+Onu8qP7J6tlRDZONmWdz57O14KO6L6vjs3o1G/vN6r5RHwZW52f9I8bGxsI4q/NHtfbTp0+H27L3hNXaZ8yYURpjr4u1bSr19Mlcvny5NMbWM7h06VJpjPUvmKiRTj7XAfzI3XebWR+Ad83sjSL2U3f/54afTUS6Bk1+dz8G4Fjx8wUz+whA3LVKRLrelK75zWwZgK8A+GNx0zNm9r6ZbTezOSXbbDWzXWa2i33UEpHOaTj5zWwmgN8A+KG7fwrgZwBWAFiL8U8GP55sO3ff5u5D7j7Ern1FpHMaSn4zuwPjif9Ld/8tALj7CXcfc/cbAH4OYF37mikirUaT38aHdb0E4CN3/8mE2yd+zfttAB+2vnki0i6NfNv/VQDfBfCBme0pbnsOwGYzW4vx8t8hAN9v5AmjEgn7TqCd3xmwEklUVmLDhdn02ex1sXJd9PhsSC4buhqVlYC4nAbEQ6XZdOqs9MvaFpV32TLYbL+wtjHR9uyxo+NtKiXIRr7t/wOAyY4gWtMXke6lHn4iSSn5RZJS8oskpeQXSUrJL5KUkl8kqY5O3e3uYR2y6jDJCKt3s6Gt58+fL42xOj+r07M+BlXjEbbP2Ws7d+5cGI+6dLPHZvVuVouvcjyx565a54/eM9buqF+Ipu4WEUrJL5KUkl8kKSW/SFJKfpGklPwiSSn5RZKydtbWv/BkZicBHJ5w03wApzrWgKnp1rZ1a7sAta1ZrWzbUndf0MgdO5r8X3hys13uPlRbAwLd2rZubRegtjWrrrbpY79IUkp+kaTqTv5tNT9/pFvb1q3tAtS2ZtXStlqv+UWkPnWf+UWkJrUkv5k9ZmYfm9knZvZsHW0oY2aHzOwDM9tjZrtqbst2Mxsxsw8n3DbXzN4ws/3F/5Muk1ZT2543s6PFvttjZhtratugmf3ezP5kZnvN7O+K22vdd0G7atlvHf/Yb2Y9APYB+AaAYQDvANjs7n/qaENKmNkhAEPuXntN2Mz+GsAogJfd/YHitn8CcMbdXyj+cM5x97/vkrY9D2C07pWbiwVlBiauLA3gCQB/ixr3XdCuJ1HDfqvjzL8OwCfufsDdrwL4FYBNNbSj67n7WwDO3HLzJgA7ip93YPzg6biStnUFdz/m7ruLny8AuLmydK37LmhXLepI/sUAjkz4fRjdteS3A/idmb1rZlvrbswk+otl0wHgOID+OhszCbpycyfdsrJ01+y7Zla8bjV94fdFD7n7XwL4JoAfFB9vu5KPX7N1U7mmoZWbO2WSlaX/rM591+yK161WR/IfBTA44fclxW1dwd2PFv+PAHgV3bf68Imbi6QW/4/U3J4/66aVmydbWRpdsO+6acXrOpL/HQArzexeM5sG4DsAdtbQji8ws97iixiYWS+ADei+1Yd3AthS/LwFwGs1tuVzumXl5rKVpVHzvuu6Fa9vzqjbyX8ANmL8G///BfAPdbShpF3LAbxX/Ntbd9sAvILxj4HXMP7dyNMA5gF4E8B+AP8NYG4Xte3fAHwA4H2MJ9pATW17COMf6d8HsKf4t7HufRe0q5b9ph5+IknpCz+RpJT8Ikkp+UWSUvKLJKXkF0lKyS+SlJJfJCklv0hS/weaQqTAHCQAhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dreamer.show(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
