Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/232_friar_30876.jpg
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/355_stony_74902.jpg
Epoch: 0, Batch : 0, Loss : 216.05775451660156
Traning accuracy : 0.0
Epoch: 0, Batch : 50, Loss : 27.50153350830078
Epoch: 0, Batch : 100, Loss : 25.984291076660156
Epoch: 0, Batch : 150, Loss : 25.22250747680664
Epoch: 0, Batch : 200, Loss : 24.716421127319336
Epoch: 0, Batch : 250, Loss : 24.560218811035156
Epoch: 0, Batch : 300, Loss : 24.399038314819336
Epoch: 0, Batch : 350, Loss : 24.23740005493164
Epoch: 0, Batch : 400, Loss : 24.031116485595703
Epoch: 0, Batch : 450, Loss : 23.98695182800293
Epoch: 0, Batch : 500, Loss : 23.62593650817871
Traning accuracy : 0.0078125
Epoch: 0, Batch : 550, Loss : 23.51062774658203
Epoch: 0, Batch : 600, Loss : 23.46866226196289
Epoch: 0, Batch : 650, Loss : 23.53156089782715
Epoch: 0, Batch : 700, Loss : 23.629114151000977
Epoch: 0, Batch : 750, Loss : 23.582338333129883
Epoch: 0, Batch : 800, Loss : 23.287857055664062
Epoch: 0, Batch : 850, Loss : 23.4921932220459
Epoch: 0, Batch : 900, Loss : 22.73505973815918
Epoch: 0, Batch : 950, Loss : 22.533411026000977
Epoch: 0, Batch : 1000, Loss : 22.37407875061035
Traning accuracy : 0.0
Epoch: 0, Batch : 1050, Loss : 21.461462020874023
Epoch: 0, Batch : 1100, Loss : 20.437707901000977
Epoch: 0, Batch : 1150, Loss : 20.45427131652832
Epoch: 0, Batch : 1200, Loss : 20.14250946044922
Epoch: 0, Batch : 1250, Loss : 17.864465713500977
Epoch: 0, Batch : 1300, Loss : 18.519105911254883
Epoch: 0, Batch : 1350, Loss : 16.483074188232422
Epoch: 0, Batch : 1400, Loss : 15.975751876831055
Epoch: 0, Batch : 1450, Loss : 14.068470001220703
Epoch: 0, Batch : 1500, Loss : 13.123678207397461
Traning accuracy : 0.328125
Epoch: 0, Batch : 1550, Loss : 11.292928695678711
Epoch: 0, Batch : 1600, Loss : 10.163311958312988
Epoch: 0, Batch : 1650, Loss : 9.399890899658203
Epoch: 0, Batch : 1700, Loss : 8.998064041137695
Epoch: 0, Batch : 1750, Loss : 7.953553199768066
Epoch: 0, Batch : 1800, Loss : 7.897197246551514
Epoch: 0, Batch : 1850, Loss : 6.921584129333496
Epoch: 0, Batch : 1900, Loss : 6.2670135498046875
Epoch: 0, Batch : 1950, Loss : 5.3659539222717285
Epoch: 0, Batch : 2000, Loss : 6.174957752227783
Traning accuracy : 0.8046875
Epoch: 0, Batch : 2050, Loss : 6.937341213226318
Epoch: 0, Batch : 2100, Loss : 5.9586591720581055
Epoch: 0, Batch : 2150, Loss : 5.886358261108398
Epoch: 0, Batch : 2200, Loss : 5.2123003005981445
Epoch: 0, Batch : 2250, Loss : 6.287159442901611
Epoch: 0, Batch : 2300, Loss : 5.001989364624023
Epoch: 0, Batch : 2350, Loss : 4.809380054473877
Epoch: 0, Batch : 2400, Loss : 5.114985466003418
Epoch: 0, Batch : 2450, Loss : 4.533404350280762
Epoch: 0, Batch : 2500, Loss : 4.162642002105713
Traning accuracy : 0.8671875
Epoch: 0, Batch : 2550, Loss : 4.890019416809082
Epoch: 0, Batch : 2600, Loss : 4.1026291847229
Epoch: 0, Batch : 2650, Loss : 2.856358289718628
Epoch: 0, Batch : 2700, Loss : 3.6804141998291016
Epoch: 0, Batch : 2750, Loss : 2.679567337036133
Epoch: 0, Batch : 2800, Loss : 3.686417818069458
Epoch: 0, Batch : 2850, Loss : 4.208794116973877
Epoch: 0, Batch : 2900, Loss : 3.5029685497283936
Epoch: 0, Batch : 2950, Loss : 3.2826743125915527
Epoch: 0, Batch : 3000, Loss : 3.931973695755005
Traning accuracy : 0.875
Epoch: 0, Batch : 3050, Loss : 3.2480618953704834
Epoch: 0, Batch : 3100, Loss : 3.072251558303833
Epoch: 0, Batch : 3150, Loss : 2.5676705837249756
Epoch: 0, Batch : 3200, Loss : 3.0218355655670166
Epoch: 0, Batch : 3250, Loss : 2.6195287704467773
Epoch: 0, Batch : 3300, Loss : 3.1908254623413086
Epoch: 0, Batch : 3350, Loss : 3.2628238201141357
Epoch: 0, Batch : 3400, Loss : 4.057123184204102
Epoch: 0, Batch : 3450, Loss : 3.312718629837036
Epoch: 0, Batch : 3500, Loss : 2.3816652297973633
Traning accuracy : 0.921875
Epoch: 0, Batch : 3550, Loss : 2.3230082988739014
Epoch: 0, Batch : 3600, Loss : 2.365229845046997
Epoch: 0, Batch : 3650, Loss : 2.3410844802856445
Epoch: 0, Batch : 3700, Loss : 2.7442092895507812
Epoch: 0, Batch : 3750, Loss : 2.198781967163086
Epoch: 0, Batch : 3800, Loss : 3.013155460357666
Epoch: 0, Batch : 3850, Loss : 2.247779369354248
Epoch: 0, Batch : 3900, Loss : 2.3765134811401367
Epoch: 0, Batch : 3950, Loss : 1.9703196287155151
End of epoch : 0, Training accuracy : 0.4755859375, Validation accuracy : 0.9239809782608696
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/232_friar_30876.jpg
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/355_stony_74902.jpg
Epoch: 1, Batch : 0, Loss : 3.143524646759033
Traning accuracy : 0.890625
Epoch: 1, Batch : 50, Loss : 2.2107584476470947
Epoch: 1, Batch : 100, Loss : 3.06260085105896
Epoch: 1, Batch : 150, Loss : 1.9877855777740479
Epoch: 1, Batch : 200, Loss : 2.3001298904418945
Epoch: 1, Batch : 250, Loss : 2.3372962474823
Epoch: 1, Batch : 300, Loss : 2.732508420944214
Epoch: 1, Batch : 350, Loss : 1.9190738201141357
Epoch: 1, Batch : 400, Loss : 1.7287577390670776
Epoch: 1, Batch : 450, Loss : 2.0790674686431885
Epoch: 1, Batch : 500, Loss : 2.420637369155884
Traning accuracy : 0.9296875
Epoch: 1, Batch : 550, Loss : 1.5499926805496216
Epoch: 1, Batch : 600, Loss : 3.1269607543945312
Epoch: 1, Batch : 650, Loss : 2.4510107040405273
Epoch: 1, Batch : 700, Loss : 2.825068235397339
Epoch: 1, Batch : 750, Loss : 2.049827814102173
Epoch: 1, Batch : 800, Loss : 1.575465440750122
Epoch: 1, Batch : 850, Loss : 1.8924068212509155
Epoch: 1, Batch : 900, Loss : 1.835334062576294
Epoch: 1, Batch : 950, Loss : 2.7127199172973633
Epoch: 1, Batch : 1000, Loss : 1.8467226028442383
Traning accuracy : 0.9375
Epoch: 1, Batch : 1050, Loss : 1.4423290491104126
Epoch: 1, Batch : 1100, Loss : 1.8158066272735596
Epoch: 1, Batch : 1150, Loss : 2.5183374881744385
Epoch: 1, Batch : 1200, Loss : 1.7702324390411377
Epoch: 1, Batch : 1250, Loss : 1.9897680282592773
Epoch: 1, Batch : 1300, Loss : 1.8269553184509277
Epoch: 1, Batch : 1350, Loss : 2.5824038982391357
Epoch: 1, Batch : 1400, Loss : 1.6158607006072998
Epoch: 1, Batch : 1450, Loss : 2.6577165126800537
Epoch: 1, Batch : 1500, Loss : 1.610581398010254
Traning accuracy : 0.953125
Epoch: 1, Batch : 1550, Loss : 1.5477668046951294
Epoch: 1, Batch : 1600, Loss : 1.395336627960205
Epoch: 1, Batch : 1650, Loss : 1.975242018699646
Epoch: 1, Batch : 1700, Loss : 2.153400421142578
Epoch: 1, Batch : 1750, Loss : 1.8186262845993042
Epoch: 1, Batch : 1800, Loss : 1.809761881828308
Epoch: 1, Batch : 1850, Loss : 2.132554769515991
Epoch: 1, Batch : 1900, Loss : 1.1295835971832275
Epoch: 1, Batch : 1950, Loss : 1.591465711593628
Epoch: 1, Batch : 2000, Loss : 2.1505978107452393
Traning accuracy : 0.9140625
Epoch: 1, Batch : 2050, Loss : 1.8367363214492798
Epoch: 1, Batch : 2100, Loss : 2.149402618408203
Epoch: 1, Batch : 2150, Loss : 1.534155011177063
Epoch: 1, Batch : 2200, Loss : 1.8266135454177856
Epoch: 1, Batch : 2250, Loss : 1.6513255834579468
Epoch: 1, Batch : 2300, Loss : 1.002211093902588
Epoch: 1, Batch : 2350, Loss : 1.2373441457748413
Epoch: 1, Batch : 2400, Loss : 2.324380874633789
Epoch: 1, Batch : 2450, Loss : 1.618876338005066
Epoch: 1, Batch : 2500, Loss : 1.1752986907958984
Traning accuracy : 0.9609375
Epoch: 1, Batch : 2550, Loss : 2.020467519760132
Epoch: 1, Batch : 2600, Loss : 1.692116141319275
Epoch: 1, Batch : 2650, Loss : 1.6766849756240845
Epoch: 1, Batch : 2700, Loss : 1.5264770984649658
Epoch: 1, Batch : 2750, Loss : 1.6560986042022705
Epoch: 1, Batch : 2800, Loss : 2.33447527885437
Epoch: 1, Batch : 2850, Loss : 1.3857126235961914
Epoch: 1, Batch : 2900, Loss : 1.2813435792922974
Epoch: 1, Batch : 2950, Loss : 1.3016016483306885
Epoch: 1, Batch : 3000, Loss : 2.2013871669769287
Traning accuracy : 0.9140625
Epoch: 1, Batch : 3050, Loss : 1.6156460046768188
Epoch: 1, Batch : 3100, Loss : 1.6424440145492554
Epoch: 1, Batch : 3150, Loss : 1.5751631259918213
Epoch: 1, Batch : 3200, Loss : 1.7347979545593262
Epoch: 1, Batch : 3250, Loss : 1.646069884300232
Epoch: 1, Batch : 3300, Loss : 1.7133607864379883
Epoch: 1, Batch : 3350, Loss : 1.4023089408874512
Epoch: 1, Batch : 3400, Loss : 1.603947639465332
Epoch: 1, Batch : 3450, Loss : 1.8339250087738037
Epoch: 1, Batch : 3500, Loss : 1.4080123901367188
Traning accuracy : 0.9609375
Epoch: 1, Batch : 3550, Loss : 1.7452869415283203
Epoch: 1, Batch : 3600, Loss : 1.5496128797531128
Epoch: 1, Batch : 3650, Loss : 1.5251870155334473
Epoch: 1, Batch : 3700, Loss : 1.890457272529602
Epoch: 1, Batch : 3750, Loss : 1.824357509613037
Epoch: 1, Batch : 3800, Loss : 1.5825974941253662
Epoch: 1, Batch : 3850, Loss : 2.4561116695404053
Epoch: 1, Batch : 3900, Loss : 1.3312747478485107
Epoch: 1, Batch : 3950, Loss : 1.455965518951416
End of epoch : 1, Training accuracy : 0.9326171875, Validation accuracy : 0.9521739130434782
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/232_friar_30876.jpg
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/355_stony_74902.jpg
Epoch: 2, Batch : 0, Loss : 1.1849555969238281
Traning accuracy : 0.9609375
Epoch: 2, Batch : 50, Loss : 0.8883148431777954
Epoch: 2, Batch : 100, Loss : 1.262068510055542
Epoch: 2, Batch : 150, Loss : 1.7147376537322998
Epoch: 2, Batch : 200, Loss : 2.105628490447998
Epoch: 2, Batch : 250, Loss : 0.8561537861824036
Epoch: 2, Batch : 300, Loss : 0.9540536999702454
Epoch: 2, Batch : 350, Loss : 1.225421667098999
Epoch: 2, Batch : 400, Loss : 1.53954017162323
Epoch: 2, Batch : 450, Loss : 1.0188766717910767
Epoch: 2, Batch : 500, Loss : 1.1750847101211548
Traning accuracy : 0.953125
Epoch: 2, Batch : 550, Loss : 0.9596762657165527
Epoch: 2, Batch : 600, Loss : 1.1603643894195557
Epoch: 2, Batch : 650, Loss : 1.5778642892837524
Epoch: 2, Batch : 700, Loss : 0.9811685085296631
Epoch: 2, Batch : 750, Loss : 1.45481276512146
Epoch: 2, Batch : 800, Loss : 1.1445417404174805
Epoch: 2, Batch : 850, Loss : 1.295009970664978
Epoch: 2, Batch : 900, Loss : 1.197502851486206
Epoch: 2, Batch : 950, Loss : 1.1908189058303833
Epoch: 2, Batch : 1000, Loss : 0.7360761761665344
Traning accuracy : 0.984375
Epoch: 2, Batch : 1050, Loss : 1.3723394870758057
Epoch: 2, Batch : 1100, Loss : 1.654155969619751
Epoch: 2, Batch : 1150, Loss : 1.7371562719345093
Epoch: 2, Batch : 1200, Loss : 1.0780869722366333
Epoch: 2, Batch : 1250, Loss : 0.9752493500709534
Epoch: 2, Batch : 1300, Loss : 0.9579731225967407
Epoch: 2, Batch : 1350, Loss : 0.8479024767875671
Epoch: 2, Batch : 1400, Loss : 0.8266258239746094
Epoch: 2, Batch : 1450, Loss : 0.8259669542312622
Epoch: 2, Batch : 1500, Loss : 1.2744673490524292
Traning accuracy : 0.96875
Epoch: 2, Batch : 1550, Loss : 1.080877661705017
Epoch: 2, Batch : 1600, Loss : 1.1475987434387207
Epoch: 2, Batch : 1650, Loss : 1.1462222337722778
Epoch: 2, Batch : 1700, Loss : 1.3451710939407349
Epoch: 2, Batch : 1750, Loss : 1.4301636219024658
Epoch: 2, Batch : 1800, Loss : 0.690873384475708
Epoch: 2, Batch : 1850, Loss : 0.9308205246925354
Epoch: 2, Batch : 1900, Loss : 0.5580607056617737
Epoch: 2, Batch : 1950, Loss : 0.6823834180831909
Epoch: 2, Batch : 2000, Loss : 0.9922440052032471
Traning accuracy : 0.9609375
Epoch: 2, Batch : 2050, Loss : 1.2004321813583374
Epoch: 2, Batch : 2100, Loss : 1.693331241607666
Epoch: 2, Batch : 2150, Loss : 1.1435834169387817
Epoch: 2, Batch : 2200, Loss : 0.8947968482971191
Epoch: 2, Batch : 2250, Loss : 1.1579110622406006
Epoch: 2, Batch : 2300, Loss : 1.6326638460159302
Epoch: 2, Batch : 2350, Loss : 1.096664547920227
Epoch: 2, Batch : 2400, Loss : 1.6600539684295654
Epoch: 2, Batch : 2450, Loss : 1.5093448162078857
Epoch: 2, Batch : 2500, Loss : 0.6319089531898499
Traning accuracy : 0.9765625
Epoch: 2, Batch : 2550, Loss : 1.8957548141479492
Epoch: 2, Batch : 2600, Loss : 1.6924878358840942
Epoch: 2, Batch : 2650, Loss : 1.7642266750335693
Epoch: 2, Batch : 2700, Loss : 0.8690581917762756
Epoch: 2, Batch : 2750, Loss : 1.358709454536438
Epoch: 2, Batch : 2800, Loss : 1.416622281074524
Epoch: 2, Batch : 2850, Loss : 1.0598114728927612
Epoch: 2, Batch : 2900, Loss : 0.8564187288284302
Epoch: 2, Batch : 2950, Loss : 1.1450048685073853
Epoch: 2, Batch : 3000, Loss : 0.9864190816879272
Traning accuracy : 0.96875
Epoch: 2, Batch : 3050, Loss : 1.2392137050628662
Epoch: 2, Batch : 3100, Loss : 0.7588663101196289
Epoch: 2, Batch : 3150, Loss : 0.76800537109375
Epoch: 2, Batch : 3200, Loss : 1.3294755220413208
Epoch: 2, Batch : 3250, Loss : 0.8742021918296814
Epoch: 2, Batch : 3300, Loss : 0.6276546716690063
Epoch: 2, Batch : 3350, Loss : 1.3454298973083496
Epoch: 2, Batch : 3400, Loss : 1.5605851411819458
Epoch: 2, Batch : 3450, Loss : 1.7657722234725952
Epoch: 2, Batch : 3500, Loss : 1.03599214553833
Traning accuracy : 0.96875
Epoch: 2, Batch : 3550, Loss : 0.8514043092727661
Epoch: 2, Batch : 3600, Loss : 0.6972936391830444
Epoch: 2, Batch : 3650, Loss : 1.459202527999878
Epoch: 2, Batch : 3700, Loss : 0.9038337469100952
Epoch: 2, Batch : 3750, Loss : 1.4782644510269165
Epoch: 2, Batch : 3800, Loss : 0.9666687250137329
Epoch: 2, Batch : 3850, Loss : 0.7786027193069458
Epoch: 2, Batch : 3900, Loss : 2.3635101318359375
Epoch: 2, Batch : 3950, Loss : 0.45170286297798157
End of epoch : 2, Training accuracy : 0.9677734375, Validation accuracy : 0.9652626811594203
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/232_friar_30876.jpg
Failed to convert  /var/tmp/on63ilaw/mjsynth/raw/355_stony_74902.jpg
Epoch: 3, Batch : 0, Loss : 0.9982206225395203
Traning accuracy : 0.96875
Epoch: 3, Batch : 50, Loss : 1.1404863595962524
Epoch: 3, Batch : 100, Loss : 0.8182780742645264
Epoch: 3, Batch : 150, Loss : 1.1812728643417358
Epoch: 3, Batch : 200, Loss : 0.9697830677032471
Epoch: 3, Batch : 250, Loss : 0.9407302141189575
Epoch: 3, Batch : 300, Loss : 0.9238020181655884
Epoch: 3, Batch : 350, Loss : 1.4669146537780762
Epoch: 3, Batch : 400, Loss : 0.4759938716888428
Epoch: 3, Batch : 450, Loss : 0.6445183157920837
Epoch: 3, Batch : 500, Loss : 0.9205997586250305
Traning accuracy : 0.96875
Epoch: 3, Batch : 550, Loss : 0.6692716479301453
Epoch: 3, Batch : 600, Loss : 0.6041228771209717
Epoch: 3, Batch : 650, Loss : 0.6125862002372742
Epoch: 3, Batch : 700, Loss : 1.093253493309021
Epoch: 3, Batch : 750, Loss : 0.59492427110672
Epoch: 3, Batch : 800, Loss : 1.119468331336975
Epoch: 3, Batch : 850, Loss : 0.42697980999946594
Epoch: 3, Batch : 900, Loss : 0.8666160702705383
Epoch: 3, Batch : 950, Loss : 0.4910282790660858
Epoch: 3, Batch : 1000, Loss : 1.0302746295928955
Traning accuracy : 0.9609375
Epoch: 3, Batch : 1050, Loss : 0.7598688006401062
Epoch: 3, Batch : 1100, Loss : 1.0572714805603027
Epoch: 3, Batch : 1150, Loss : 0.9631502628326416
Epoch: 3, Batch : 1200, Loss : 0.8876588940620422
Epoch: 3, Batch : 1250, Loss : 0.7809695601463318
Epoch: 3, Batch : 1300, Loss : 1.1610100269317627
Epoch: 3, Batch : 1350, Loss : 0.9423632025718689
Epoch: 3, Batch : 1400, Loss : 1.0451594591140747
Epoch: 3, Batch : 1450, Loss : 1.0755562782287598
Epoch: 3, Batch : 1500, Loss : 0.6956873536109924
Traning accuracy : 0.96875
Epoch: 3, Batch : 1550, Loss : 1.0026370286941528
Epoch: 3, Batch : 1600, Loss : 0.770047664642334
Epoch: 3, Batch : 1650, Loss : 1.0934666395187378
Epoch: 3, Batch : 1700, Loss : 0.577421247959137
Epoch: 3, Batch : 1750, Loss : 0.6037391424179077
Epoch: 3, Batch : 1800, Loss : 1.0057272911071777
Epoch: 3, Batch : 1850, Loss : 1.104494571685791
Epoch: 3, Batch : 1900, Loss : 0.6179563403129578
Epoch: 3, Batch : 1950, Loss : 1.0339478254318237
Epoch: 3, Batch : 2000, Loss : 0.6181737780570984
Traning accuracy : 0.9765625
Epoch: 3, Batch : 2050, Loss : 0.9410765171051025
Epoch: 3, Batch : 2100, Loss : 0.48342591524124146
Epoch: 3, Batch : 2150, Loss : 1.1411305665969849
Epoch: 3, Batch : 2200, Loss : 1.0264860391616821
Epoch: 3, Batch : 2250, Loss : 0.7033311128616333
Epoch: 3, Batch : 2300, Loss : 0.7854145765304565
Epoch: 3, Batch : 2350, Loss : 0.7296594381332397
Epoch: 3, Batch : 2400, Loss : 0.8695758581161499
Epoch: 3, Batch : 2450, Loss : 0.9763574600219727
Epoch: 3, Batch : 2500, Loss : 0.38242465257644653
Traning accuracy : 0.9921875
Epoch: 3, Batch : 2550, Loss : 1.303066611289978
Epoch: 3, Batch : 2600, Loss : 0.8621094226837158
Epoch: 3, Batch : 2650, Loss : 1.1353918313980103
Epoch: 3, Batch : 2700, Loss : 0.5965703129768372
Epoch: 3, Batch : 2750, Loss : 0.5989561676979065
Epoch: 3, Batch : 2800, Loss : 0.8328297138214111
Epoch: 3, Batch : 2850, Loss : 0.6131654381752014
Epoch: 3, Batch : 2900, Loss : 0.9658780694007874
Epoch: 3, Batch : 2950, Loss : 0.7786096334457397
Epoch: 3, Batch : 3000, Loss : 0.8921410441398621
Traning accuracy : 0.9609375
Epoch: 3, Batch : 3050, Loss : 0.9062830209732056
Epoch: 3, Batch : 3100, Loss : 1.9060375690460205
Epoch: 3, Batch : 3150, Loss : 0.9064538478851318
Epoch: 3, Batch : 3200, Loss : 1.0779496431350708
Epoch: 3, Batch : 3250, Loss : 1.0417603254318237
Epoch: 3, Batch : 3300, Loss : 0.6416516900062561
Epoch: 3, Batch : 3350, Loss : 0.8320636749267578
Epoch: 3, Batch : 3400, Loss : 1.1400222778320312
Epoch: 3, Batch : 3450, Loss : 1.2521079778671265
Epoch: 3, Batch : 3500, Loss : 0.5990332961082458
Traning accuracy : 0.9921875
Epoch: 3, Batch : 3550, Loss : 1.4872183799743652
Epoch: 3, Batch : 3600, Loss : 0.8465440273284912
Epoch: 3, Batch : 3650, Loss : 1.2299410104751587
Epoch: 3, Batch : 3700, Loss : 1.1705782413482666
Epoch: 3, Batch : 3750, Loss : 0.747270941734314
Epoch: 3, Batch : 3800, Loss : 0.5174463391304016
Epoch: 3, Batch : 3850, Loss : 0.7613348960876465
Epoch: 3, Batch : 3900, Loss : 1.6297341585159302
Epoch: 3, Batch : 3950, Loss : 0.944202184677124
End of epoch : 3, Training accuracy : 0.9736328125, Validation accuracy : 0.9652626811594203
Epoch: 4, Batch : 0, Loss : 0.6215968132019043
Traning accuracy : 0.984375
Epoch: 4, Batch : 50, Loss : 0.41435447335243225
Epoch: 4, Batch : 100, Loss : 0.9334967732429504
Epoch: 4, Batch : 150, Loss : 0.9031396508216858
Epoch: 4, Batch : 200, Loss : 0.38473811745643616
Epoch: 4, Batch : 250, Loss : 0.7175717353820801
Epoch: 4, Batch : 300, Loss : 0.5773159265518188
Epoch: 4, Batch : 350, Loss : 1.1054619550704956
Epoch: 4, Batch : 400, Loss : 0.6122384667396545
Epoch: 4, Batch : 450, Loss : 0.6142846345901489
Epoch: 4, Batch : 500, Loss : 0.3477005958557129
Traning accuracy : 0.9921875
Epoch: 4, Batch : 550, Loss : 0.6651658415794373
Epoch: 4, Batch : 600, Loss : 0.7183938026428223
Epoch: 4, Batch : 650, Loss : 0.5343778133392334
Epoch: 4, Batch : 700, Loss : 0.7625579237937927
Epoch: 4, Batch : 750, Loss : 1.044407844543457
Epoch: 4, Batch : 800, Loss : 0.7478816509246826
Epoch: 4, Batch : 850, Loss : 0.8802807331085205
Epoch: 4, Batch : 900, Loss : 0.6244874000549316
Epoch: 4, Batch : 950, Loss : 0.6214996576309204
Epoch: 4, Batch : 1000, Loss : 0.6568406820297241
Traning accuracy : 0.953125
Epoch: 4, Batch : 1050, Loss : 0.7984580397605896
Epoch: 4, Batch : 1100, Loss : 0.5321140885353088
Epoch: 4, Batch : 1150, Loss : 0.754934549331665
Epoch: 4, Batch : 1200, Loss : 0.17598280310630798
Epoch: 4, Batch : 1250, Loss : 0.5348595380783081
Epoch: 4, Batch : 1300, Loss : 0.7172095775604248
Epoch: 4, Batch : 1350, Loss : 0.6578909158706665
Epoch: 4, Batch : 1400, Loss : 0.3161630630493164
Epoch: 4, Batch : 1450, Loss : 0.6763773560523987
Epoch: 4, Batch : 1500, Loss : 0.8315011262893677
Traning accuracy : 0.96875
Epoch: 4, Batch : 1550, Loss : 0.4606860280036926
Epoch: 4, Batch : 1600, Loss : 1.0978760719299316
Epoch: 4, Batch : 1650, Loss : 0.6672119498252869
Epoch: 4, Batch : 1700, Loss : 0.4482351541519165
Epoch: 4, Batch : 1750, Loss : 0.7013003826141357
Epoch: 4, Batch : 1800, Loss : 0.30099937319755554
Epoch: 4, Batch : 1850, Loss : 0.9576963782310486
Epoch: 4, Batch : 1900, Loss : 0.4141763746738434
Epoch: 4, Batch : 1950, Loss : 1.0384018421173096
Epoch: 4, Batch : 2000, Loss : 0.6620951294898987
Traning accuracy : 0.984375
Epoch: 4, Batch : 2050, Loss : 0.5705096125602722
Epoch: 4, Batch : 2100, Loss : 0.5798593759536743
Epoch: 4, Batch : 2150, Loss : 0.7055661082267761
Epoch: 4, Batch : 2200, Loss : 0.8783245086669922
Epoch: 4, Batch : 2250, Loss : 0.8339051604270935
Epoch: 4, Batch : 2300, Loss : 0.6636779308319092
Epoch: 4, Batch : 2350, Loss : 1.032607078552246
Epoch: 4, Batch : 2400, Loss : 0.8270143270492554
Epoch: 4, Batch : 2450, Loss : 0.7904177904129028
Epoch: 4, Batch : 2500, Loss : 0.40668925642967224
Traning accuracy : 0.9921875
Epoch: 4, Batch : 2550, Loss : 0.5862327814102173
Epoch: 4, Batch : 2600, Loss : 0.5733405947685242
Epoch: 4, Batch : 2650, Loss : 0.7252453565597534
Epoch: 4, Batch : 2700, Loss : 0.6687955856323242
Epoch: 4, Batch : 2750, Loss : 1.0295960903167725
Epoch: 4, Batch : 2800, Loss : 0.8130329251289368
Epoch: 4, Batch : 2850, Loss : 0.48709139227867126
Epoch: 4, Batch : 2900, Loss : 0.8320846557617188
Epoch: 4, Batch : 2950, Loss : 0.4413144886493683
Epoch: 4, Batch : 3000, Loss : 0.5431215167045593
Traning accuracy : 0.984375
Epoch: 4, Batch : 3050, Loss : 0.7717264890670776
Epoch: 4, Batch : 3100, Loss : 1.5550453662872314
Epoch: 4, Batch : 3150, Loss : 0.6013986468315125
