{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/cip/ce/on63ilaw/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/cip/ce/on63ilaw/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findtags(tag_prefix, tagged_text):\n",
    "    \"\"\"\n",
    "    Find tokens matching the specified tag_prefix\n",
    "    \"\"\"\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].keys()[:5]) for tag in cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_9 = sorted([w for w in open(\"/proj/cipdata/on63ilaw/mjsynth/subset_dataset/create_dataset_files/lexicon.txt\").read().strip().split(\"\\n\") if (len(w)==9) and (not hasNumbers(w))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12366"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lex_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aardvarks',\n",
       " 'abandoned',\n",
       " 'abasement',\n",
       " 'abashedly',\n",
       " 'abashment',\n",
       " 'abatement',\n",
       " 'abattoirs',\n",
       " 'abdicated',\n",
       " 'abdicates',\n",
       " 'abdominal']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_9[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5827"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_9.index('islamabad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_9_random_200 = random.choices(lex_9,k=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lex_9_random_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['endurance',\n",
       " 'goatskins',\n",
       " 'restrains',\n",
       " 'thickened',\n",
       " 'hungering',\n",
       " 'sailcloth',\n",
       " 'agreement',\n",
       " 'entrapped',\n",
       " 'discovers',\n",
       " 'mandating']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_9_random_200[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('lex_len9_random_200.txt', 'w') as f:\n",
    "#     for item in lex_9_random_200:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_syntactic_lex_9 = [w for w in lex_9 if 'q' in w or 'z' in w or 'ae' in w or 'oe' in w or 'ue'\n",
    "in w or 'gu' in w or 'ay' in w or 'ke' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aconcagua',\n",
       " 'acquaints',\n",
       " 'acquiesce',\n",
       " 'acquirers',\n",
       " 'acquiring',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'actualize',\n",
       " 'aerialist',\n",
       " 'aerobatic']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_syntactic_lex_9[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1244"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exclude_syntactic_lex_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_9mod=sorted(set([w[0].upper()+w[1:].lower() for w in lex_9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_9mod_tokenized = [nltk.word_tokenize(w) for w in lex_9mod]\n",
    "# # clean up html into raw text\n",
    "# lRaw = nltk.clean_html(lHtml)\n",
    "\n",
    "# # Tokenize the raw text \n",
    "# lTokens = nltk.word_tokenize(lRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "lTokens = [nltk.pos_tag(w) for w in lex_9mod_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Abandoned', 'VBN')]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lTokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12366"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Invoicing', 'VBG')],\n",
       " [('Involving', 'VBG')],\n",
       " [('Iphigenia', 'NN')],\n",
       " [('Irascible', 'JJ')],\n",
       " [('Irascibly', 'RB')],\n",
       " [('Irateness', 'NN')],\n",
       " [('Irksomely', 'RB')],\n",
       " [('Ironclads', 'NNS')],\n",
       " [('Ironstone', 'NN')],\n",
       " [('Ironwoods', 'NNS')],\n",
       " [('Iroquoian', 'JJ')],\n",
       " [('Irradiate', 'NN')],\n",
       " [('Irrawaddy', 'NNP')],\n",
       " [('Irregular', 'JJ')],\n",
       " [('Irrigable', 'JJ')],\n",
       " [('Irrigated', 'VBN')],\n",
       " [('Irrigates', 'NNS')],\n",
       " [('Irritable', 'JJ')],\n",
       " [('Irritably', 'RB')],\n",
       " [('Irritants', 'NNS')],\n",
       " [('Irritated', 'VBN')],\n",
       " [('Irritates', 'NNS')],\n",
       " [('Irrupting', 'VBG')],\n",
       " [('Irruption', 'NN')],\n",
       " [('Irruptive', 'JJ')],\n",
       " [('Isherwood', 'NN')],\n",
       " [('Isinglass', 'NN')],\n",
       " [('Islamabad', 'NN')],\n",
       " [('Islanders', 'NNS')],\n",
       " [('Isolating', 'VBG')],\n",
       " [('Isolation', 'NN')],\n",
       " [('Isomerism', 'NN')],\n",
       " [('Isometric', 'JJ')],\n",
       " [('Isosceles', 'NNS')],\n",
       " [('Isotherms', 'NNS')],\n",
       " [('Isotropic', 'NN')],\n",
       " [('Israelite', 'NN')],\n",
       " [('Isthmuses', 'NNS')],\n",
       " [('Italicize', 'VB')],\n",
       " [('Itchiness', 'NN')],\n",
       " [('Itemizing', 'VBG')],\n",
       " [('Iterating', 'VBG')],\n",
       " [('Iteration', 'NN')],\n",
       " [('Iterative', 'JJ')],\n",
       " [('Iterators', 'NNS')],\n",
       " [('Itinerant', 'NN')],\n",
       " [('Itinerary', 'JJ')],\n",
       " [('Jabberers', 'NNS')],\n",
       " [('Jabbering', 'VBG')],\n",
       " [('Jacaranda', 'NN')]]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lTokens[5800:5850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_semantic_lex_9mod = [x[0][0] for x in lTokens if x[0][1]=='NNP']\n",
    "# for tag in sorted(lTagDict):\n",
    "#     print (tag, lTagDict[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exclude_semantic_lex_9mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinia',\n",
       " 'Acclaimed',\n",
       " 'Acidified',\n",
       " 'Affianced',\n",
       " 'Agrippina',\n",
       " 'Agronomic',\n",
       " 'Akhmatova',\n",
       " 'Alejandra',\n",
       " 'Alexandra',\n",
       " 'Ambergris',\n",
       " 'Amnestied',\n",
       " 'Amplified',\n",
       " 'Anaerobic',\n",
       " 'Anchorite',\n",
       " 'Annabelle',\n",
       " 'Aphrodite',\n",
       " 'Appraiser',\n",
       " 'Archangel',\n",
       " 'Archibald',\n",
       " 'Argentina',\n",
       " 'Aristotle',\n",
       " 'Arlington',\n",
       " 'Armstrong',\n",
       " 'Astraddle',\n",
       " 'Atrophied',\n",
       " 'Australia',\n",
       " 'Automaton',\n",
       " 'Autonomic',\n",
       " 'Autopsied',\n",
       " 'Babylonia',\n",
       " 'Backboard',\n",
       " 'Backpedal',\n",
       " 'Badminton',\n",
       " 'Bagatelle',\n",
       " 'Bailiwick',\n",
       " 'Baksheesh',\n",
       " 'Baldfaced',\n",
       " 'Ballerina',\n",
       " 'Bamboozle',\n",
       " 'Barcelona',\n",
       " 'Barefaced',\n",
       " 'Barhopped',\n",
       " 'Barracuda',\n",
       " 'Baseboard',\n",
       " 'Beardsley',\n",
       " 'Beastlier',\n",
       " 'Bedridden',\n",
       " 'Beefaroni',\n",
       " 'Beethoven',\n",
       " 'Belvedere',\n",
       " 'Bernoulli',\n",
       " 'Bernstein',\n",
       " 'Bertolini',\n",
       " 'Bestrewed',\n",
       " 'Bethlehem',\n",
       " 'Betrothal',\n",
       " 'Billboard',\n",
       " 'Billowier',\n",
       " 'Biosphere',\n",
       " 'Bipartite',\n",
       " 'Bishopric',\n",
       " 'Blackwell',\n",
       " 'Blanchard',\n",
       " 'Blarneyed',\n",
       " 'Bloodshot',\n",
       " 'Blotchier',\n",
       " 'Bluebeard',\n",
       " 'Blueberry',\n",
       " 'Bobsleigh',\n",
       " 'Bodyguard',\n",
       " 'Boldfaced',\n",
       " 'Boltzmann',\n",
       " 'Bombshell',\n",
       " 'Bondwoman',\n",
       " 'Boogeyman',\n",
       " 'Boogieman',\n",
       " 'Boomerang',\n",
       " 'Bordellos',\n",
       " 'Boulevard',\n",
       " 'Bourgeois',\n",
       " 'Bramblier',\n",
       " 'Brasserie',\n",
       " 'Brassiere',\n",
       " 'Bratwurst',\n",
       " 'Breakaway',\n",
       " 'Breastfed',\n",
       " 'Breathier',\n",
       " 'Breezeway',\n",
       " 'Brickyard',\n",
       " 'Bridleway',\n",
       " 'Brigadier',\n",
       " 'Bristlier',\n",
       " 'Britannia',\n",
       " 'Brunswick',\n",
       " 'Buckboard',\n",
       " 'Budweiser',\n",
       " 'Buffaloed',\n",
       " 'Butterier',\n",
       " 'Carpenter',\n",
       " 'Casuelita',\n",
       " 'Catnapped',\n",
       " 'Chihuahua',\n",
       " 'Chirruped',\n",
       " 'Chlamydia',\n",
       " 'Christina',\n",
       " 'Clambered',\n",
       " 'Clapeyron',\n",
       " 'Cleopatra',\n",
       " 'Coalesced',\n",
       " 'Cobwebbed',\n",
       " 'Commenced',\n",
       " 'Committee',\n",
       " 'Community',\n",
       " 'Confabbed',\n",
       " 'Corneille',\n",
       " 'Courtesan',\n",
       " 'Cyclotron',\n",
       " 'Debriefed',\n",
       " 'Decollete',\n",
       " 'Denounced',\n",
       " 'Describer',\n",
       " 'Disgraced',\n",
       " 'Dishcloth',\n",
       " 'Dismember',\n",
       " 'Displaced',\n",
       " 'Distanced',\n",
       " 'Disturbed',\n",
       " 'Disturber',\n",
       " 'Doorknobs',\n",
       " 'Ensconced',\n",
       " 'Entranced',\n",
       " 'Facecloth',\n",
       " 'Flummoxed',\n",
       " 'Francisco',\n",
       " 'Frankfurt',\n",
       " 'Gabrielle',\n",
       " 'Gallerias',\n",
       " 'Galveston',\n",
       " 'Gardenias',\n",
       " 'Gaucherie',\n",
       " 'Gelignite',\n",
       " 'Genitalia',\n",
       " 'Genocidal',\n",
       " 'Geometric',\n",
       " 'Geriatric',\n",
       " 'Ghastlier',\n",
       " 'Ghostlier',\n",
       " 'Glassfuls',\n",
       " 'Goldbrick',\n",
       " 'Gondolier',\n",
       " 'Gonorrhea',\n",
       " 'Goolagong',\n",
       " 'Gorbachev',\n",
       " 'Granville',\n",
       " 'Graybeard',\n",
       " 'Greenhorn',\n",
       " 'Greenspan',\n",
       " 'Greenwich',\n",
       " 'Grenadier',\n",
       " 'Gristlier',\n",
       " 'Grizzlier',\n",
       " 'Grouchier',\n",
       " 'Grunewald',\n",
       " 'Guillermo',\n",
       " 'Gutenberg',\n",
       " 'Haircloth',\n",
       " 'Hampshire',\n",
       " 'Harmonica',\n",
       " 'Headfirst',\n",
       " 'Henderson',\n",
       " 'Hiroshima',\n",
       " 'Hobnobbed',\n",
       " 'Hollywood',\n",
       " 'Homegrown',\n",
       " 'Honeywell',\n",
       " 'Hundredth',\n",
       " 'Hurricane',\n",
       " 'Hyperbola',\n",
       " 'Hypocrite',\n",
       " 'Indochina',\n",
       " 'Inscriber',\n",
       " 'Institute',\n",
       " 'Interpret',\n",
       " 'Interrupt',\n",
       " 'Irrawaddy',\n",
       " 'Jarlsberg',\n",
       " 'Kagoshima',\n",
       " 'Kalamazoo',\n",
       " 'Kamchatka',\n",
       " 'Kampuchea',\n",
       " 'Kandinsky',\n",
       " 'Kangaroos',\n",
       " 'Kaohsiung',\n",
       " 'Karaganda',\n",
       " 'Karakorum',\n",
       " 'Karamazov',\n",
       " 'Kartouche',\n",
       " 'Katherine',\n",
       " 'Kathiawar',\n",
       " 'Kathmandu',\n",
       " 'Keelhauls',\n",
       " 'Kerfuffle',\n",
       " 'Keystroke',\n",
       " 'Khwarizmi',\n",
       " 'Kibbutzim',\n",
       " 'Kickstand',\n",
       " 'Kidnapped',\n",
       " 'Kidnapper',\n",
       " 'Kilohertz',\n",
       " 'Kilowatts',\n",
       " 'Kimberley',\n",
       " 'Kingstown',\n",
       " 'Kinswoman',\n",
       " 'Kirchhoff',\n",
       " 'Kirghizia',\n",
       " 'Kirinyaga',\n",
       " 'Kisangani',\n",
       " 'Kissogram',\n",
       " 'Kitchener',\n",
       " 'Knockdown',\n",
       " 'Knoxville',\n",
       " 'Korzybski',\n",
       " 'Kosciusko',\n",
       " 'Kropotkin',\n",
       " 'Kshatriya',\n",
       " 'Kuibyshev',\n",
       " 'Kurdistan',\n",
       " 'Lederberg',\n",
       " 'Lexington',\n",
       " 'Lithuania',\n",
       " 'Ljubljana',\n",
       " 'Loincloth',\n",
       " 'Louisiana',\n",
       " 'Lusitania',\n",
       " 'Macdonald',\n",
       " 'Macintosh',\n",
       " 'Maladroit',\n",
       " 'Manhattan',\n",
       " 'Margarita',\n",
       " 'Marijuana',\n",
       " 'Maryellen',\n",
       " 'Massasoit',\n",
       " 'Mcconnell',\n",
       " 'Mcdonnell',\n",
       " 'Microsoft',\n",
       " 'Misplaced',\n",
       " 'Misplayed',\n",
       " 'Misshaped',\n",
       " 'Misshapen',\n",
       " 'Misspoken',\n",
       " 'Monterrey',\n",
       " 'Morphemic',\n",
       " 'Multiplex',\n",
       " 'Mussolini',\n",
       " 'Nashville',\n",
       " 'Nonmember',\n",
       " 'Organelle',\n",
       " 'Outnumber',\n",
       " 'Oversexed',\n",
       " 'Overtaxed',\n",
       " 'Pankhurst',\n",
       " 'Panoramic',\n",
       " 'Paramount',\n",
       " 'Perplexed',\n",
       " 'Pinkerton',\n",
       " 'President',\n",
       " 'Professor',\n",
       " 'Quadrille',\n",
       " 'Robertson',\n",
       " 'Rosenberg',\n",
       " 'Sackcloth',\n",
       " 'Sailcloth',\n",
       " 'Secretary',\n",
       " 'September',\n",
       " 'Sharkskin',\n",
       " 'Sheepskin',\n",
       " 'Signorina',\n",
       " 'Singapore',\n",
       " 'Snakeskin',\n",
       " 'Supernova',\n",
       " 'Taxonomic',\n",
       " 'Venezuela',\n",
       " 'Verdigris',\n",
       " 'Viceregal',\n",
       " 'Vouchsafe',\n",
       " 'Washcloth',\n",
       " 'Wednesday',\n",
       " 'Wikipedia',\n",
       " 'Wycherley',\n",
       " 'Zsigmondy']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_semantic_lex_9mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
